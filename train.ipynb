{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]}},"cells":[{"metadata":{"id":"EZ9kVYG_pDrK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oLSYqWPXqBiL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JbZ6c-u4pQTz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once per notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Download a file based on its file ID.\n","#\n","# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n","file_id = '1AyULTkscFRSlZIJ143yXe7qg8fSNPBp-'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('util.py')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oi_UBeiIqXEZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once per notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Download a file based on its file ID.\n","#\n","# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n","file_id = '1IugJe_XgxWtVkim24TlGz36YiUwGX13D'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('alexnet.py')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nC9oqA5TqdtI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import sys\n","import os.path\n","import time\n","import alexnet\n","import tensorflow as tf\n","import util as tu\n","import numpy as np\n","import threading"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KN_dUJF6q1oh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def train(threads_numbers,epochs,batch_size,learning_rate,dropout,lmbda,resume,imagenet_path,display_step,test_step,ckpt_path,summary_path):\n","  \"\"\"Procedure to train the model on ImageNet ILSVRC 2012 training set\n","        Args:\n","            resume: boolean variable,true if want to resume the training ,false to train from scratch\n","            imagenet_path: path to ILSVRC12 ImageNet folder containing train images,\n","                              validation images, annotations and metadata file\n","            display_step:number representing how often printing the current training accuracy\n","            test_step: number representing how often make a test and print the validation accuracy\n","            ckpt_path: path where to save model's tensorflow checkpoint(or from where resume)\n","            summary_path: path where to save logs for Tensorboard\n","  \"\"\"\n","  train_img_path = os.path.join(imagenet_path,'ILSVRC2012_img_train')\n","  ts_size = tu.imagenet_size(train_img_path)\n","  num_batches = int(float(ts_size)/batch_size)\n","  \n","  wnids_labels,_ = tu.load_imagenet_meta(os.path,join(imagenet_path,'data/meta.mat'))\n","  with tf.device('/gpu:0'):\n","    x = tf.placeholder(tf.float32,[None,224,224,3])\n","    y = tf.placeholder(tf.float32,[None,1000])\n","    lr = tf.placeholder(tf.float32)\n","    keep_prob = tf.placeholder(tf.float32)\n","    \n","  #queue of examples being filled on the cpu\n","  \n","  with tf.device('/cpu:0'):\n","    q = tf.FIFOQueue(batch_size*3,[tf.float32,tf.float32],shapes = [[224,224,3],[1000]])\n","    enqueue_op = q.enqueue_many([x,y])\n","    x_b,y_b = q.dequeue_many(batch_size)\n","    \n","  pred,_ =alexnet.classifier(x_b,keep_prob)\n","  with tf.device('/gpu:0'):\n","    # cross-entorpy and weight decay\n","    with tf.name_scope('cross_entorpy'):\n","      cross_entropy =tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= pred,labels = y_b,name = 'cross-entropy'))\n","  \n","    with tf.name_scope('l2_loss'):\n","      l2_loss = tf.reduce_sum(lmbda*tf.stack([tf.nn.l2_loss(v) for v in tf.get_collection('weights')]))\n","      tf.summary.scalar('l2_loss',l2_loss)\n","      \n","    with tf.name_scope('loss'):\n","      loss = cross_entrop+l2_loss\n","      tf.summary.scalar('loss',loss)\n","    \n","    #accuracy\n","    with tf.name_scope('accuracy'):\n","      correct = tf.equal(tf.argmax(pred,1),tf.argmax(y_b,1))\n","      accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n","      tf.summary.scalar('accuracy',accuracy)\n","      \n","    global_step = tf.Variable(0,trainable = False)\n","    epoch = tf.div(global_step,num_batches)\n","    \n","    #momentum optimizer\n","    with tf.name_scope('optimizer'):\n","      optimizer = tf.train.AdamOptimizer(learning_rate = lr).minize(loss,global_step = global_step)\n","      \n","    #merge summaries to write them to file\n","    merged = tf.summary.merge_all()\n","    \n","    #checkpoint saver\n","    saver = tf.train.Saver()\n","    \n","    \n","    coord = tf.train.Coordinator()\n","    \n","    #init = tf.initialize_all_variables()\n","    init = tf.global_variables_initializer()\n","    \n","  with tf.Session(config = tf.ConfigProto(allow_soft_placement = True,log_device_placement =True)) as sess:\n","    if resume:\n","      saver.restore(sess,os.path.join(ckpt_path,'alexnet-cnn.ckpt'))\n","    else:\n","      sess.run(init)\n","      \n","    #enqueing batches procedure\n","    def enqueue_batches():\n","      while not coord.should_stop():\n","        im,l = tu.read_batch(batch_size,train_img_path,wnid_labels)\n","        sess.run(enqueue_op,feed_dict={x:im,y:1})\n","        \n","    #creating and starting parallel threads to fill the queue\n","    num_threads = threads_numbers\n","    \n","    for i in range(num_threads):\n","      t = threading.Thread(target = enqueue_batches)\n","      t.setDaemon(True)\n","      t.start()\n","      \n","    #operation to write logs for tensorboard visualization\n","    train_writer = tf.summary.FileWriter(os.path.join(summary_path,'train'),sess.graph)\n","    \n","    start_time = time.time()\n","    \n","    for e in range(sess.run(epoch),epochs):\n","      \n","      for i in range(num_batches):\n","        _,step = sess.run([optimizer,global_step],feed_dict = {lr: learning_rate,keep_prob: dropout})\n","        #train_writer.add_summary(summary,step)\n","        \n","        \n","        #decaying learning rate\n","        if step == 170000 or step == 350000:\n","          learning_rate /= 10\n","          \n","        # display current training informations\n","        if step% display_step == 0:\n","          temp_time = time.time()\n","          c,a = sess.run([loss,accuracy],feed_dict = {lr:learning_rate,keep_prob:1.0})\n","          print(\"time: \",temp_time-start_time,'Epoch: {:03d} Step/Batch: {:09d} --- Loss: {:.7f} Training accuracy: {:.4f}'.format(e,step,c,a))\n","          \n","        # make test and evaluate validation accuracy\n","        if step% test_step == 0:\n","          val_im,val_cls = tu.read_validation_batch(batch_size,os.path.join(imagenet_path,'ILSVRC2012_img_val'),os.path.join(imagenet_path,'data/ILSVRC2012_validation_ground_truth.txt'))\n","          v_a = sess.run(accuracy,feed_dict = {x_b:val_im,y_b:val_cls,lr:learning_rate,keep_prob:1.0})\n","          #intermediate time\n","          int_time = time.time()\n","          print('Elapsed time: {}'.format(tu.format(tu.format_time(int_time- start_time))))\n","          print('Validation accuracy: {:.04f}'.format(v_a))\n","          \n","          #save weights to file\n","          \n","          save_path = saver.save(sess,os.path.join(ckpt_path,'alexnet-cnn.ckpt'))\n","          print('Variables saved in file: %s'% save_path)\n","          \n","    end_time = time.time()\n","    print('Elapsed time:{}'.format(tu.format_time(end_time-start_time)))\n","    save_path = saver.save(sess,os.path.join(ckpt_path,'alexnet-cnn.ckpt'))\n","    print('Variables saved in file:%s' % save_path)\n","    \n","    coord.request_stop()\n","    \n","if __name__ == '__main__'    :\n","  Threads_numbers = 4\n","  DROPOUT = 0.5\n","  LAMBDA = 5e-05 #for weight decay\n","  LEARNING_RATE = 1e-03\n","  EPOCHS = 90\n","  BATCH_SIZE = 128\n","  CKPT_PATH = 'ckpt-alexnet'\n","  \n","  if not os.path.exists(CKPT_PATH):\n","    os.makedirs(CKPT_PATH)\n","  \n","  SUMMARY = 'summary'\n","  \n","  if not os.path.exists(SUMMARY):\n","    os.makedirs(SUMMARY)\n","    \n","  IMAGENET_PATH = 'F64E50644E502023/ILSVRC2012'\n","  DISPLAY_STEP = 10\n","  TEST_STEP = 500\n","  if len(sys.argv) == 1:\n","    resume = False\n","    \n","  elif sys.argv[1] == '-resume':\n","    resume = True\n","    \n","  train(Threads_numbers,EPOCHS,BATCH_SIZE,LEARNING_RATE,DROPOUT,LAMBDA,resume,IMAGENET_PATH,DISPLAY_STEP,TEST_STEP,CKPT_PATH,SUMMARY)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cqH7AQd8dYz-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}